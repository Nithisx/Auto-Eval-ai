{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44fefa4a",
   "metadata": {},
   "source": [
    "\n",
    "# Answer Sheet — Group by Question Number **with Horizontal Line Stops** (EasyOCR, EXIF-safe)\n",
    "\n",
    "Improved grouping:\n",
    "- Detects **question numbers** in the **left strip** and starts a new group.\n",
    "- Also detects **horizontal separator lines**. If a line appears after a question, that line **ends the current group**, even if the next question number is farther down.\n",
    "- Transparent overlay; EXIF-aware; no page warp by default.\n",
    "\n",
    "Outputs: `debug_overlay.png`, `crops/word_####.png`, `words.json`, `groups_index.json`, `groups/Q###/` folders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0361e49",
   "metadata": {},
   "source": [
    "\n",
    "## Install (run locally)\n",
    "```bash\n",
    "pip install easyocr opencv-python numpy pillow\n",
    "# (Optional GPU) install torch+CUDA first, then: pip install easyocr\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "239e6716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT_PATH: E:\\EvaluationAI\\Dataset\\29.jpg\n",
      "OUTPUT_DIR: E:\\EvaluationAI\\autoevalaioutputs5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Paths ---\n",
    "INPUT_PATH = Path(r\"E:\\EvaluationAI\\Dataset\\29.jpg\")\n",
    "OUTPUT_DIR = Path(r\"E:\\EvaluationAI\\autoevalaioutputs5\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Orientation & alignment ---\n",
    "RESPECT_EXIF       = True\n",
    "ALIGN_TO_A4        = False\n",
    "A4_SIZE_PX         = (2480, 3508)\n",
    "\n",
    "# --- Detection (EasyOCR/CRAFT) ---\n",
    "USE_GPU            = False\n",
    "TEXT_THRESHOLD     = 0.7\n",
    "LINK_THRESHOLD     = 0.4\n",
    "LOW_TEXT           = 0.4\n",
    "MIN_SIZE           = 5\n",
    "WORD_PAD           = 2\n",
    "MIN_AREA_PX        = 30\n",
    "\n",
    "# --- Left strip recognition (anchors) ---\n",
    "LEFT_STRIP_R_INIT  = 0.32   # scan up to 32% width for numbers\n",
    "ANCHOR_CONF_MIN    = 0.32\n",
    "ANCHOR_REGEXES     = [\n",
    "    r\"^\\(?\\d{1,2}\\)?$\",\n",
    "    r\"^\\(?\\d{1,2}\\)?[.)]$\",\n",
    "    r\"^[Qq]\\s*\\d{1,2}[.)]?$\",\n",
    "]\n",
    "\n",
    "# --- Grouping / border ---\n",
    "LEFT_PAD_PX        = 12\n",
    "TOP_PAD            = 6\n",
    "BOTTOM_PAD         = 6\n",
    "\n",
    "# --- Horizontal line detection ---\n",
    "MIN_LINE_REL_LEN   = 0.55   # line must span >=55% of width\n",
    "MAX_LINE_REL_THK   = 0.02   # thickness <=2% of height\n",
    "MERGE_LINE_TOL_PX  = 12     # merge nearby lines within 12px\n",
    "\n",
    "print(\"INPUT_PATH:\", INPUT_PATH)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "757c8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, math, re\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "def read_image_exif_bgr(path: Path) -> np.ndarray:\n",
    "    im = Image.open(path)\n",
    "    im = ImageOps.exif_transpose(im)\n",
    "    im = im.convert(\"RGB\")\n",
    "    arr = np.array(im)\n",
    "    return cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def ensure_img(path: Path) -> np.ndarray:\n",
    "    if RESPECT_EXIF:\n",
    "        return read_image_exif_bgr(path)\n",
    "    img = cv2.imread(str(path))\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Could not load image: {path}\")\n",
    "    return img\n",
    "\n",
    "def save_image(img_bgr: np.ndarray, name: str) -> Path:\n",
    "    p = OUTPUT_DIR / name\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cv2.imwrite(str(p), img_bgr)\n",
    "    return p\n",
    "\n",
    "def save_json(obj: Any, name: str) -> Path:\n",
    "    p = OUTPUT_DIR / name\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(p, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2, ensure_ascii=False)\n",
    "    return p\n",
    "\n",
    "def poly_to_bbox(poly: np.ndarray) -> Tuple[int,int,int,int]:\n",
    "    xs = poly[:,0]; ys = poly[:,1]\n",
    "    x0 = int(np.floor(xs.min())); y0 = int(np.floor(ys.min()))\n",
    "    x1 = int(np.ceil(xs.max()));  y1 = int(np.ceil(ys.max()))\n",
    "    return x0,y0,x1,y1\n",
    "\n",
    "def save_crop(img: np.ndarray, bbox_xyxy, path: Path):\n",
    "    x0,y0,x1,y1 = bbox_xyxy\n",
    "    h, w = img.shape[:2]\n",
    "    x0 = max(0,x0); y0 = max(0,y0); x1 = min(w-1, x1); y1 = min(h-1, y1)\n",
    "    if x1 > x0 and y1 > y0:\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        cv2.imwrite(str(path), img[y0:y1, x0:x1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614cb255",
   "metadata": {},
   "source": [
    "### Transparent overlay helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96885ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_transparent_overlay(base_bgr, word_polys, anchor_boxes, x_border, sep_lines):\n",
    "    H, W = base_bgr.shape[:2]\n",
    "    canvas = base_bgr.copy()\n",
    "    layer  = base_bgr.copy()\n",
    "\n",
    "    # words (green)\n",
    "    for poly in word_polys:\n",
    "        cv2.polylines(layer, [poly.astype(np.int32)], True, (0,255,0), 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "    # anchor boxes (blue)\n",
    "    for (x0,y0,x1,y1,text,conf) in anchor_boxes:\n",
    "        cv2.rectangle(layer, (x0,y0), (x1,y1), (255,128,0), 1, lineType=cv2.LINE_AA)\n",
    "        cv2.putText(layer, text, (x0, max(0,y0-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,128,0), 1, cv2.LINE_AA)\n",
    "\n",
    "    # horizontal separators (cyan)\n",
    "    for y in sep_lines:\n",
    "        cv2.line(layer, (0, y), (W-1, y), (255, 255, 0), 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "    # vertical border (orange)\n",
    "    cv2.line(layer, (x_border, 0), (x_border, H-1), (0,165,255), 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "    alpha = 0.55\n",
    "    cv2.addWeighted(layer, alpha, canvas, 1-alpha, 0, canvas)\n",
    "    return canvas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e4c2da",
   "metadata": {},
   "source": [
    "### EasyOCR detector (boxes) + left-strip recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fb8b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import easyocr\n",
    "\n",
    "_reader = None\n",
    "def get_reader():\n",
    "    global _reader\n",
    "    if _reader is None:\n",
    "        _reader = easyocr.Reader(['en'], gpu=USE_GPU, verbose=False)\n",
    "    return _reader\n",
    "\n",
    "def detect_words(img_bgr: np.ndarray) -> List[np.ndarray]:\n",
    "    reader = get_reader()\n",
    "    rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    results = reader.readtext(\n",
    "        rgb,\n",
    "        detail=1,\n",
    "        paragraph=False,\n",
    "        min_size=MIN_SIZE,\n",
    "        text_threshold=TEXT_THRESHOLD,\n",
    "        low_text=LOW_TEXT,\n",
    "        link_threshold=LINK_THRESHOLD\n",
    "    )\n",
    "    polys: List[np.ndarray] = []\n",
    "    for item in results:\n",
    "        poly = np.array(item[0], dtype=np.float32)\n",
    "        if poly.ndim == 2 and poly.shape[0] >= 4:\n",
    "            polys.append(poly)\n",
    "    return polys\n",
    "\n",
    "def find_number_like(text: str) -> bool:\n",
    "    t = text.strip()\n",
    "    pats = [\n",
    "        r\"^\\(?\\d{1,2}\\)?$\",\n",
    "        r\"^\\(?\\d{1,2}\\)?[.)]$\",\n",
    "        r\"^[Qq]\\s*\\d{1,2}[.)]?$\",\n",
    "    ]\n",
    "    return any(re.match(p, t) for p in pats)\n",
    "\n",
    "def recognize_left_strip(img_bgr: np.ndarray, xr: float) -> List[Tuple[int,int,int,int,str,float]]:\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    x_max = int(max(1, min(W-1, xr * W)))\n",
    "    crop = img_bgr[:, :x_max].copy()\n",
    "    reader = get_reader()\n",
    "    rgb = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "    results = reader.readtext(\n",
    "        rgb,\n",
    "        detail=1,\n",
    "        paragraph=False,\n",
    "        min_size=MIN_SIZE,\n",
    "        text_threshold=TEXT_THRESHOLD,\n",
    "        low_text=LOW_TEXT,\n",
    "        link_threshold=LINK_THRESHOLD\n",
    "    )\n",
    "    out = []\n",
    "    for poly, text, conf in results:\n",
    "        if conf < ANCHOR_CONF_MIN:\n",
    "            continue\n",
    "        if not find_number_like(text):\n",
    "            continue\n",
    "        poly = np.array(poly, dtype=np.float32)\n",
    "        x0,y0,x1,y1 = poly_to_bbox(poly)\n",
    "        out.append((x0, y0, x1, y1, text, float(conf)))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567e3557",
   "metadata": {},
   "source": [
    "### Horizontal separator line detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dec7378",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_horizontal_separators(img_bgr: np.ndarray,\n",
    "                                 min_rel_len=MIN_LINE_REL_LEN,\n",
    "                                 max_rel_thk=MAX_LINE_REL_THK,\n",
    "                                 merge_tol=MERGE_LINE_TOL_PX) -> List[int]:\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    g = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    # adaptive binary (text/lines white on dark background)\n",
    "    bw = cv2.adaptiveThreshold(g, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                               cv2.THRESH_BINARY_INV, 35, 10)\n",
    "    H, W = bw.shape[:2]\n",
    "    klen = max(30, int(W * 0.35))\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (klen, 1))\n",
    "    morph = cv2.morphologyEx(bw, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    morph = cv2.dilate(morph, np.ones((3,3), np.uint8), iterations=1)\n",
    "\n",
    "    # contours as candidate lines\n",
    "    cnts = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    ys = []\n",
    "    for c in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        if w >= min_rel_len * W and h <= max_rel_thk * H:\n",
    "            ys.append(int(y + h/2))\n",
    "\n",
    "    if not ys:\n",
    "        # fallback with Hough on edges\n",
    "        edges = cv2.Canny(g, 50, 150, apertureSize=3)\n",
    "        lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=160,\n",
    "                                minLineLength=int(min_rel_len*W),\n",
    "                                maxLineGap=12)\n",
    "        if lines is not None:\n",
    "            for l in lines[:,0]:\n",
    "                x1,y1,x2,y2 = l.tolist()\n",
    "                if abs(y1 - y2) <= int(max_rel_thk * H):\n",
    "                    ys.append(int((y1+y2)/2))\n",
    "\n",
    "    if not ys:\n",
    "        return []\n",
    "\n",
    "    ys = sorted(ys)\n",
    "    merged = []\n",
    "    for y in ys:\n",
    "        if not merged or abs(y - merged[-1]) > merge_tol:\n",
    "            merged.append(y)\n",
    "        else:\n",
    "            merged[-1] = int((merged[-1] + y)/2)\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fed57b0",
   "metadata": {},
   "source": [
    "## Pipeline: detect → left numbers → separators → border → grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d492dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Border x = 1281 | anchors=0 | separators=1 | words=88\n",
      "Q001 | y_range=[6, 1165] | anchor=None | words=13\n",
      "Q002 | y_range=[1177, 4009] | anchor=None | words=37\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_pipeline():\n",
    "    img = ensure_img(INPUT_PATH)\n",
    "    H, W = img.shape[:2]\n",
    "\n",
    "    # 1) Word polygons\n",
    "    polys = detect_words(img)\n",
    "\n",
    "    # 2) Left-strip numbers (anchors)\n",
    "    anchors_raw = recognize_left_strip(img, LEFT_STRIP_R_INIT)\n",
    "    anchors_raw.sort(key=lambda t: (t[1]+t[3]) / 2.0)\n",
    "\n",
    "    # dedupe nearby anchors\n",
    "    deduped = []\n",
    "    for a in anchors_raw:\n",
    "        cy = (a[1]+a[3]) / 2.0\n",
    "        if deduped and abs(((deduped[-1][1]+deduped[-1][3])/2.0) - cy) < 18:\n",
    "            prev = deduped[-1]\n",
    "            prev_area = (prev[2]-prev[0])*(prev[3]-prev[1])\n",
    "            curr_area = (a[2]-a[0])*(a[3]-a[1])\n",
    "            if curr_area > prev_area:\n",
    "                deduped[-1] = a\n",
    "        else:\n",
    "            deduped.append(a)\n",
    "    anchors_raw = deduped\n",
    "\n",
    "    # 3) All word records (+ crops)\n",
    "    words = []\n",
    "    crops_dir = OUTPUT_DIR / \"crops\"\n",
    "    idx = 1\n",
    "    for poly in polys:\n",
    "        x0,y0,x1,y1 = poly_to_bbox(poly)\n",
    "        if (x1-x0)*(y1-y0) < MIN_AREA_PX:\n",
    "            continue\n",
    "        cx = (x0+x1)/2.0; cy = (y0+y1)/2.0\n",
    "        fname = f\"word_{idx:04d}.png\"\n",
    "        save_crop(img, (x0,y0,x1,y1), crops_dir / fname)\n",
    "        words.append({\n",
    "            \"id\": idx,\n",
    "            \"poly\": poly.round(2).tolist(),\n",
    "            \"bbox_xyxy\": [int(x0),int(y0),int(x1),int(y1)],\n",
    "            \"center\": [float(cx), float(cy)],\n",
    "            \"size\": [int(x1-x0), int(y1-y0)],\n",
    "            \"crop_path\": str((crops_dir / fname).as_posix())\n",
    "        })\n",
    "        idx += 1\n",
    "\n",
    "    # 4) Horizontal separator lines\n",
    "    seps = detect_horizontal_separators(img)\n",
    "\n",
    "    # 5) Border: to the right of question numbers if present; else safe heuristic\n",
    "    if anchors_raw:\n",
    "        right_edges = [a[2] for a in anchors_raw]\n",
    "        x_border = int(np.percentile(np.array(right_edges), 95) + LEFT_PAD_PX)\n",
    "        x_border = min(max(x_border, int(0.08*W)), int(0.5*W))\n",
    "    else:\n",
    "        xs = [w[\"center\"][0] for w in words if w[\"center\"][0] <= 0.5*W]\n",
    "        x_border = int((np.percentile(xs, 95) if xs else 0.28*W) + LEFT_PAD_PX)\n",
    "\n",
    "    # 6) Build anchor structs\n",
    "    anchors = []\n",
    "    for (x0,y0,x1,y1,text,conf) in anchors_raw:\n",
    "        cx = (x0+x1)/2.0; cy = (y0+y1)/2.0\n",
    "        anchors.append({\"bbox_xyxy\":[x0,y0,x1,y1], \"center\":[float(cx), float(cy)], \"text\":text, \"conf\":conf})\n",
    "    anchors.sort(key=lambda a: a[\"center\"][1])\n",
    "\n",
    "    # 7) Overlay\n",
    "    overlay = draw_transparent_overlay(\n",
    "        img,\n",
    "        [np.array(w[\"poly\"], dtype=np.float32) for w in words],\n",
    "        [(a[\"bbox_xyxy\"][0],a[\"bbox_xyxy\"][1],a[\"bbox_xyxy\"][2],a[\"bbox_xyxy\"][3], a[\"text\"], a[\"conf\"]) for a in anchors],\n",
    "        x_border,\n",
    "        seps\n",
    "    )\n",
    "    save_image(overlay, \"debug_overlay.png\")\n",
    "\n",
    "    # 8) Group using separators as hard stops\n",
    "    groups = []\n",
    "    prev_bottom = 0\n",
    "    for i, anc in enumerate(anchors):\n",
    "        a_y = int(anc[\"center\"][1])\n",
    "\n",
    "        # next anchor y (if any)\n",
    "        next_a_y = int(anchors[i+1][\"center\"][1]) if i+1 < len(anchors) else H-1\n",
    "\n",
    "        # first separator line below current anchor\n",
    "        sep_candidates = [y for y in seps if y > a_y + 8]   # a small offset\n",
    "        sep_y = min(sep_candidates) if sep_candidates else None\n",
    "\n",
    "        # choose end boundary: the **earliest** among next separator, mid to next anchor, bottom\n",
    "        mid_to_next_anchor = int((a_y + next_a_y)/2)\n",
    "        y_end = min([v for v in [sep_y, mid_to_next_anchor, H-1] if v is not None])\n",
    "\n",
    "        # start boundary is previous group's end (with padding)\n",
    "        y_start = max(0, prev_bottom + TOP_PAD)\n",
    "        y_end   = max(y_start+1, y_end - BOTTOM_PAD)  # ensure increasing\n",
    "\n",
    "        grp_dir = OUTPUT_DIR / \"groups\" / f\"Q{i+1:03d}\"\n",
    "        grp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        ax0,ay0,ax1,ay1 = anc[\"bbox_xyxy\"]\n",
    "        save_crop(img, (ax0,ay0,ax1,ay1), grp_dir / \"anchor.png\")\n",
    "\n",
    "        pack = {\"group\": f\"Q{i+1:03d}\", \"y_range\": [int(y_start), int(y_end)],\n",
    "                \"anchor_text\": anc[\"text\"], \"anchor_conf\": anc[\"conf\"],\n",
    "                \"anchor_box\": anc[\"bbox_xyxy\"], \"words\": []}\n",
    "\n",
    "        for w in words:\n",
    "            cx, cy = w[\"center\"]\n",
    "            if cx > x_border and y_start <= cy <= y_end:\n",
    "                src = Path(w[\"crop_path\"]); dst = grp_dir / Path(src).name\n",
    "                im = cv2.imread(str(src))\n",
    "                if im is not None: cv2.imwrite(str(dst), im)\n",
    "                pack[\"words\"].append({**w, \"group_path\": str(dst.as_posix())})\n",
    "        groups.append(pack)\n",
    "        prev_bottom = y_end\n",
    "\n",
    "    if not anchors:\n",
    "        # fallback single band using separators only\n",
    "        bands = [0] + seps + [H-1]\n",
    "        for bi in range(len(bands)-1):\n",
    "            y0 = bands[bi] + TOP_PAD\n",
    "            y1 = bands[bi+1] - BOTTOM_PAD\n",
    "            if y1 <= y0: continue\n",
    "            grp_dir = OUTPUT_DIR / \"groups\" / f\"Q{bi+1:03d}\"\n",
    "            grp_dir.mkdir(parents=True, exist_ok=True)\n",
    "            pack = {\"group\": f\"Q{bi+1:03d}\", \"y_range\": [int(y0), int(y1)],\n",
    "                    \"anchor_text\": None, \"anchor_conf\": None, \"anchor_box\": None, \"words\": []}\n",
    "            for w in words:\n",
    "                cx, cy = w[\"center\"]\n",
    "                if cx > x_border and y0 <= cy <= y1:\n",
    "                    src = Path(w[\"crop_path\"]); dst = grp_dir / Path(src).name\n",
    "                    im = cv2.imread(str(src))\n",
    "                    if im is not None: cv2.imwrite(str(dst), im)\n",
    "                    pack[\"words\"].append({**w, \"group_path\": str(dst.as_posix())})\n",
    "            groups.append(pack)\n",
    "\n",
    "    save_json({\"border_x\": x_border, \"width\": W, \"height\": H, \"words\": words}, \"words.json\")\n",
    "    save_json({\"anchors\": anchors, \"separators\": seps, \"groups\": groups}, \"groups_index.json\")\n",
    "\n",
    "    print(f\"Border x = {x_border} | anchors={len(anchors)} | separators={len(seps)} | words={len(words)}\")\n",
    "    for g in groups:\n",
    "        print(f\"{g['group']} | y_range={g['y_range']} | anchor={g.get('anchor_text')} | words={len(g['words'])}\")\n",
    "\n",
    "run_pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9ee8b0",
   "metadata": {},
   "source": [
    "## Inspect outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1c4e217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:/EvaluationAI/autoevalaioutputs5/crops/word_0001.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0002.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0003.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0004.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0005.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0006.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0007.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0008.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0009.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0010.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0011.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0012.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0013.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0014.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0015.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0016.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0017.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0018.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0019.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0020.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0021.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0022.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0023.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0024.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0025.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0026.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0027.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0028.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0029.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0030.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0031.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0032.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0033.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0034.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0035.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0036.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0037.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0038.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0039.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0040.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0041.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0042.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0043.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0044.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0045.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0046.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0047.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0048.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0049.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0050.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0051.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0052.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0053.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0054.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0055.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0056.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0057.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0058.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0059.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs5/crops/word_0060.png']\n",
      "... total files: 141\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pprint import pprint\n",
    "files = sorted([p.as_posix() for p in OUTPUT_DIR.rglob(\"*\") if p.is_file()])\n",
    "pprint(files[:60])\n",
    "print(\"... total files:\", len(files))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
