{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d22229b",
   "metadata": {},
   "source": [
    "\n",
    "# Answer Sheet — Word Segmentation & Grouping (**EasyOCR CRAFT**, No Paddle)\n",
    "\n",
    "This notebook segments **every word** using **EasyOCR**'s CRAFT detector (recognition ignored) and groups right-side words by **left-column anchors** separated by a vertical **border**.\n",
    "\n",
    "**Highlights**\n",
    "- **EXIF-aware** image loading (fixes rotation mismatches)\n",
    "- Optional page **warp off** (so overlays don't shift/hide tokens)\n",
    "- **Transparent** overlay (no boxes covering text)\n",
    "- Auto or fixed **border**; outputs per-anchor groups (`groups/Q001`, `Q002`, …)\n",
    "- Saves: `debug_overlay.png`, `crops/word_####.png`, `words.json`, `groups_index.json`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039e4456",
   "metadata": {},
   "source": [
    "\n",
    "## Install (run locally, not here)\n",
    "```bash\n",
    "pip install easyocr opencv-python numpy pillow\n",
    "# Optional GPU (install torch+CUDA first)\n",
    "# pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
    "# then: pip install easyocr\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43ece0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT_PATH: E:\\EvaluationAI\\Dataset\\30.jpg\n",
      "OUTPUT_DIR: E:\\EvaluationAI\\autoevalaioutputs30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Paths ---\n",
    "INPUT_PATH = Path(r\"E:\\EvaluationAI\\Dataset\\30.jpg\")     # change if needed\n",
    "OUTPUT_DIR = Path(r\"E:\\EvaluationAI\\autoevalaioutputs30\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Orientation & alignment ---\n",
    "RESPECT_EXIF       = True     # read with EXIF rotation\n",
    "ALIGN_TO_A4        = False    # keep False to avoid overlay shifts while debugging\n",
    "A4_SIZE_PX         = (2480, 3508)  # (W, H) if you later enable warping\n",
    "\n",
    "# --- Detection params (EasyOCR -> CRAFT under the hood) ---\n",
    "USE_GPU            = False\n",
    "TEXT_THRESHOLD     = 0.7\n",
    "LINK_THRESHOLD     = 0.4\n",
    "LOW_TEXT           = 0.4\n",
    "MIN_SIZE           = 5         # min text height\n",
    "WORD_PAD           = 2         # pad around each bbox\n",
    "MIN_AREA_PX        = 30        # drop tiny boxes\n",
    "\n",
    "# --- Border / anchors ---\n",
    "BORDER_MODE        = \"fixed\"   # \"fixed\" or \"auto\"\n",
    "FIXED_BORDER_RATIO = 0.26      # 26% of width; tune per template\n",
    "LEFT_PAD_PX        = 12        # when auto: push border slightly right of anchors\n",
    "\n",
    "# --- Grouping pads ---\n",
    "TOP_PAD            = 6\n",
    "BOTTOM_PAD         = 6\n",
    "\n",
    "print(\"INPUT_PATH:\", INPUT_PATH)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "850c373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, math\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "def read_image_exif_bgr(path: Path) -> np.ndarray:\n",
    "    im = Image.open(path)\n",
    "    im = ImageOps.exif_transpose(im)  # respect EXIF orientation\n",
    "    im = im.convert(\"RGB\")\n",
    "    arr = np.array(im)                # RGB\n",
    "    return cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def ensure_img(path: Path) -> np.ndarray:\n",
    "    if RESPECT_EXIF:\n",
    "        return read_image_exif_bgr(path)\n",
    "    img = cv2.imread(str(path))\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Could not load image: {path}\")\n",
    "    return img\n",
    "\n",
    "def save_image(img_bgr: np.ndarray, name: str) -> Path:\n",
    "    p = OUTPUT_DIR / name\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cv2.imwrite(str(p), img_bgr)\n",
    "    return p\n",
    "\n",
    "def save_json(obj: Any, name: str) -> Path:\n",
    "    p = OUTPUT_DIR / name\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(p, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2, ensure_ascii=False)\n",
    "    return p\n",
    "\n",
    "def poly_to_bbox(poly: np.ndarray) -> Tuple[int,int,int,int]:\n",
    "    xs = poly[:,0]; ys = poly[:,1]\n",
    "    x0 = int(np.floor(xs.min())); y0 = int(np.floor(ys.min()))\n",
    "    x1 = int(np.ceil(xs.max()));  y1 = int(np.ceil(ys.max()))\n",
    "    return x0,y0,x1,y1\n",
    "\n",
    "def save_crop(img: np.ndarray, bbox_xyxy, path: Path):\n",
    "    x0,y0,x1,y1 = bbox_xyxy\n",
    "    h, w = img.shape[:2]\n",
    "    x0 = max(0,x0); y0 = max(0,y0); x1 = min(w-1, x1); y1 = min(h-1, y1)\n",
    "    if x1 > x0 and y1 > y0:\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        cv2.imwrite(str(path), img[y0:y1, x0:x1])\n",
    "\n",
    "def draw_transparent_boxes(base_bgr, polys, anchors, x_border):\n",
    "    H, W = base_bgr.shape[:2]\n",
    "    canvas = base_bgr.copy()\n",
    "    layer  = base_bgr.copy()\n",
    "\n",
    "    # all word polygons (green)\n",
    "    for poly in polys:\n",
    "        cv2.polylines(layer, [poly.astype(np.int32)], True, (0,255,0), 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "    # anchors (red thin)\n",
    "    for a in anchors:\n",
    "        x0,y0,x1,y1 = a[\"bbox_xyxy\"]\n",
    "        cv2.rectangle(layer, (x0,y0), (x1,y1), (0,0,255), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "    # border (orange)\n",
    "    cv2.line(layer, (x_border, 0), (x_border, H-1), (0,165,255), 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "    # blend to avoid hiding text\n",
    "    alpha = 0.55\n",
    "    cv2.addWeighted(layer, alpha, canvas, 1-alpha, 0, canvas)\n",
    "    return canvas\n",
    "\n",
    "def auto_border_from_left(words, W, pad_px=12):\n",
    "    xs = [w[\"center\"][0] for w in words if w[\"center\"][0] <= 0.5*W]\n",
    "    if not xs:\n",
    "        return int(0.28 * W)\n",
    "    left_edge = int(np.percentile(xs, 95)) + pad_px\n",
    "    return min(max(left_edge, int(0.10*W)), int(0.80*W))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b0f828",
   "metadata": {},
   "source": [
    "## EasyOCR detector (boxes only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0559cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import easyocr\n",
    "\n",
    "_reader = None\n",
    "def get_reader():\n",
    "    global _reader\n",
    "    if _reader is None:\n",
    "        _reader = easyocr.Reader(['en'], gpu=USE_GPU, verbose=False)\n",
    "    return _reader\n",
    "\n",
    "def run_easyocr_detector(img_bgr: np.ndarray) -> List[np.ndarray]:\n",
    "    reader = get_reader()\n",
    "    rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    results = reader.readtext(\n",
    "        rgb,\n",
    "        detail=1,               # [[poly, text, conf], ...]\n",
    "        paragraph=False,\n",
    "        min_size=MIN_SIZE,\n",
    "        text_threshold=TEXT_THRESHOLD,\n",
    "        low_text=LOW_TEXT,\n",
    "        link_threshold=LINK_THRESHOLD\n",
    "    )\n",
    "    polys: List[np.ndarray] = []\n",
    "    for item in results:\n",
    "        poly = np.array(item[0], dtype=np.float32)\n",
    "        if poly.ndim == 2 and poly.shape[0] >= 4:\n",
    "            polys.append(poly)\n",
    "    return polys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47b28bc",
   "metadata": {},
   "source": [
    "## Run segmentation → border → grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ffd9023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Border x = 636 (W=2448) | anchors=14 | total words=79\n",
      "Q001: 5 right-side words; y_range=[257, 713]\n",
      "Q002: 9 right-side words; y_range=[725, 1034]\n",
      "Q003: 5 right-side words; y_range=[1046, 1246]\n",
      "Q004: 4 right-side words; y_range=[1258, 1416]\n",
      "Q005: 0 right-side words; y_range=[1428, 1569]\n",
      "Q006: 1 right-side words; y_range=[1581, 1853]\n",
      "Q007: 12 right-side words; y_range=[1865, 2146]\n",
      "Q008: 3 right-side words; y_range=[2158, 2343]\n",
      "Q009: 5 right-side words; y_range=[2355, 2602]\n",
      "Q010: 6 right-side words; y_range=[2614, 2886]\n",
      "Q011: 3 right-side words; y_range=[2898, 3190]\n",
      "Q012: 10 right-side words; y_range=[3202, 3461]\n",
      "Q013: 0 right-side words; y_range=[3473, 3555]\n",
      "Q014: 2 right-side words; y_range=[3567, 3721]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_pipeline():\n",
    "    img = ensure_img(INPUT_PATH)\n",
    "\n",
    "    H, W = img.shape[:2]\n",
    "    polys = run_easyocr_detector(img)\n",
    "\n",
    "    words = []\n",
    "    crops_dir = OUTPUT_DIR / \"crops\"\n",
    "    idx = 1\n",
    "    for poly in polys:\n",
    "        x0,y0,x1,y1 = poly_to_bbox(poly)\n",
    "        if (x1-x0)*(y1-y0) < MIN_AREA_PX:\n",
    "            continue\n",
    "        cx = (x0+x1)/2.0; cy = (y0+y1)/2.0\n",
    "        fname = f\"word_{idx:04d}.png\"\n",
    "        save_crop(img, (x0,y0,x1,y1), crops_dir / fname)\n",
    "        words.append({\n",
    "            \"id\": idx,\n",
    "            \"poly\": poly.round(2).tolist(),\n",
    "            \"bbox_xyxy\": [int(x0),int(y0),int(x1),int(y1)],\n",
    "            \"center\": [float(cx), float(cy)],\n",
    "            \"size\": [int(x1-x0), int(y1-y0)],\n",
    "            \"crop_path\": str((crops_dir / fname).as_posix())\n",
    "        })\n",
    "        idx += 1\n",
    "\n",
    "    # border\n",
    "    if BORDER_MODE == \"fixed\":\n",
    "        x_border = int(FIXED_BORDER_RATIO * W)\n",
    "    else:\n",
    "        x_border = auto_border_from_left(words, W, pad_px=LEFT_PAD_PX)\n",
    "\n",
    "    # anchors\n",
    "    anchors = [w for w in words if w[\"center\"][0] <= x_border]\n",
    "    anchors.sort(key=lambda w: w[\"center\"][1])\n",
    "\n",
    "    # overlay\n",
    "    overlay = draw_transparent_boxes(\n",
    "        img,\n",
    "        [np.array(w[\"poly\"], dtype=np.float32) for w in words],\n",
    "        anchors,\n",
    "        x_border\n",
    "    )\n",
    "    save_image(overlay, \"debug_overlay.png\")\n",
    "\n",
    "    # grouping\n",
    "    groups = []\n",
    "    if anchors:\n",
    "        edges_y = [0] + [int(a[\"center\"][1]) for a in anchors] + [H-1]\n",
    "        bounds = []\n",
    "        for i in range(1, len(edges_y)-1):\n",
    "            y_mid_prev = int((edges_y[i-1] + edges_y[i]) / 2)\n",
    "            y_mid_next = int((edges_y[i]   + edges_y[i+1]) / 2)\n",
    "            y0 = max(0, y_mid_prev + TOP_PAD)\n",
    "            y1 = min(H-1, y_mid_next - BOTTOM_PAD)\n",
    "            bounds.append((i, y0, y1))\n",
    "\n",
    "        for gi, y0, y1 in bounds:\n",
    "            grp_dir = OUTPUT_DIR / \"groups\" / f\"Q{gi:03d}\"\n",
    "            grp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            anc = anchors[gi-1]\n",
    "            ax0,ay0,ax1,ay1 = anc[\"bbox_xyxy\"]\n",
    "            save_crop(img, (ax0,ay0,ax1,ay1), grp_dir / \"anchor.png\")\n",
    "\n",
    "            pack = {\"group\": f\"Q{gi:03d}\", \"y_range\": [y0,y1], \"anchor_id\": anc[\"id\"], \"words\": []}\n",
    "            for w in words:\n",
    "                cx, cy = w[\"center\"]\n",
    "                if cx > x_border and y0 <= cy <= y1:\n",
    "                    src = Path(w[\"crop_path\"]); dst = grp_dir / Path(src).name\n",
    "                    im = cv2.imread(str(src))\n",
    "                    if im is not None: cv2.imwrite(str(dst), im)\n",
    "                    pack[\"words\"].append({**w, \"group_path\": str(dst.as_posix())})\n",
    "            groups.append(pack)\n",
    "    else:\n",
    "        grp_dir = OUTPUT_DIR / \"groups\" / \"Q001\"\n",
    "        grp_dir.mkdir(parents=True, exist_ok=True)\n",
    "        pack = {\"group\": \"Q001\", \"y_range\": [0,H-1], \"anchor_id\": None, \"words\": []}\n",
    "        for w in words:\n",
    "            cx = w[\"center\"][0]\n",
    "            if cx > x_border:\n",
    "                src = Path(w[\"crop_path\"]); dst = grp_dir / Path(src).name\n",
    "                im = cv2.imread(str(src))\n",
    "                if im is not None: cv2.imwrite(str(dst), im)\n",
    "                pack[\"words\"].append({**w, \"group_path\": str(dst.as_posix())})\n",
    "        groups.append(pack)\n",
    "\n",
    "    save_json({\"border_x\": x_border, \"width\": W, \"height\": H, \"words\": words}, \"words.json\")\n",
    "    save_json({\"groups\": groups}, \"groups_index.json\")\n",
    "\n",
    "    print(f\"Border x = {x_border} (W={W}) | anchors={len(anchors)} | total words={len(words)}\")\n",
    "    for g in groups:\n",
    "        print(f\"{g['group']}: {len(g['words'])} right-side words; y_range={g['y_range']}\")\n",
    "\n",
    "run_pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa61a87",
   "metadata": {},
   "source": [
    "## Inspect outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f32d8e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:/EvaluationAI/autoevalaioutputs30/crops/word_0001.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0002.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0003.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0004.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0005.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0006.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0007.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0008.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0009.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0010.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0011.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0012.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0013.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0014.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0015.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0016.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0017.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0018.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0019.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0020.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0021.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0022.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0023.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0024.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0025.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0026.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0027.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0028.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0029.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0030.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0031.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0032.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0033.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0034.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0035.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0036.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0037.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0038.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0039.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0040.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0041.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0042.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0043.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0044.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0045.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0046.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0047.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0048.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0049.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0050.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0051.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0052.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0053.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0054.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0055.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0056.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0057.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0058.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0059.png',\n",
      " 'E:/EvaluationAI/autoevalaioutputs30/crops/word_0060.png']\n",
      "... total files: 161\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pprint import pprint\n",
    "files = sorted([p.as_posix() for p in OUTPUT_DIR.rglob(\"*\") if p.is_file()])\n",
    "pprint(files[:60])\n",
    "print(\"... total files:\", len(files))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
